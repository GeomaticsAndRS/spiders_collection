# spiders_collection
用于存放一些爬虫脚本

## 01 猫眼电影-最受期待榜榜单
### 实现功能：

1. 使用requests库爬取榜单
2. 分析第1步获取的HTML数据，使用正则表达式过滤采集需要的信息字段，使用生成器存储字段数据，加上re.S参数连换行符一起输出
3. 存储到log文件中
4. 多线程爬取

### 遇到的问题：

1. get请求没有加User-Agent的header，爬虫被拒绝访问，添加后解决

### 未解决问题：

1. 期待度的2个数字不显示

**原因**：源代码中展示的并不是纯粹的数字。而是在页面使用了font-face定义了字符集，并通过unicode去映射展示。简单介绍下这种新型的web-fongt反爬虫机制：使用web-font可以从网络加载字体

[解决方案](http://www.freebuf.com/news/140965.html/1)

### 收获：

1. 学会了基本的requests操作，请求和分析一个静态页面
2. 学会了基本的正则表达式操作，通过()获取得到不同的关键字，提取得到需要的信息
3. 基本的写入文本文件操作
4. 遇到最简单的反爬虫，加入header参数里面的user-agent即可
5. 最简单的多线程抓取，map函数的使用
6. 字符串转JSON生成字典，使用json.loads()方法
7. 用生成器存储算法，而不是直接生成字典，避免存储空间浪费，在需要用到数据的时候，使用for循环调用生成器生成数据即可
8. 保存到文件使用中文的时候，open方法中要使用encoding='utf-0'，write方法中要使用ensure_ascii=False)


## 02 今日头条-采集和下载关键词“新垣结衣”的图集图片
### 实现功能：

1. 使用requests库爬取得到首页信息，返回的HTML代码中不包含需要的信息，都是些JS
2. 在XHR中找到JSON请求和数据
3. 使用request.get方法请求JSON数据，使用urlencode()生成完成的URL
4. 在第3步中得到一个字符串，使用json.loads()方法生成字典形式的JSON变量，通过keys()方法获取需要的标题信息，定义成生成器，得到所有的
5. 使用for循环调用第4步中的生成器，返回每个文章的url，传递给请求详情页的函数
6. 如果请求到了详情页，那么解析详情页，需要从返回的HTML代码中获取字段信息，因此采用BeautifulSoup进行解析
7. 用bs的select()方法获取title，并用get_text()取出第一个内容
8. 使用正则表达式从解析后的页面中找到图片地址，返回的是一个字符串
9. 第一次用json.load()返回的依然是1个字符串，需要嵌套多1层json.load()
10. 在第9步返回的JSON变量中，使用get()方法提取所有图片的地址，返回一个list，再使用for循环，遍历返回的list，得到所有图片的下载地址，并下载，把结果保存到MongoDB

### 遇到的问题：

1. 第9步的字符串也是反爬的手段之一，需要使用2次json.loads()

### 未解决问题：

无

### 收获
1. 分析AJAX返回的网页
2. 使用BeautifulSoup解析网页，并获取需要的信息
3. 字符串转JSON常量
4. 保存图片


